{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dill\n",
    "# !pip install ktext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import dill as dpickle\n",
    "\n",
    "from ktext.preprocess import processor\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_files(data_path:str):\n",
    "    \"\"\"\n",
    "    Read data from directory\n",
    "    \"\"\"\n",
    "    PATH = Path(data_path)\n",
    "\n",
    "    with open(PATH/'train.function', 'r') as f:\n",
    "        t_enc = f.readlines()\n",
    "\n",
    "    with open(PATH/'valid.function', 'r') as f:\n",
    "        v_enc = f.readlines()\n",
    "\n",
    "    # combine train and validation and let keras split it randomly for you\n",
    "    tv_enc = t_enc + v_enc\n",
    "\n",
    "    with open(PATH/'test.function', 'r') as f:\n",
    "        h_enc = f.readlines()\n",
    "\n",
    "    with open(PATH/'train.docstring', 'r') as f:\n",
    "        t_dec = f.readlines()\n",
    "\n",
    "    with open(PATH/'valid.docstring', 'r') as f:\n",
    "        v_dec = f.readlines()\n",
    "\n",
    "    # combine train and validation and let keras split it randomly for you\n",
    "    tv_dec = t_dec + v_dec\n",
    "\n",
    "    with open(PATH/'test.docstring', 'r') as f:\n",
    "        h_dec = f.readlines()\n",
    "\n",
    "    return tv_enc, h_enc, tv_dec, h_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_code, holdout_code, train_docstring, holdout_docstring = read_training_files('processed_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def batch_generator batch_size data labels None n_batches int np ceil len data float batch_size idx np random permutation len data data_shuffled data idx if labels is not None labels_shuffled labels idx for i in range n_batches start i batch_size end start batch_size if labels is not None yield data_shuffled start end labels_shuffled start end else yield data_shuffled start end\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_code[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"generates batches of samples : param data : array - like , shape = ( n_samples , n_features ) : param labels : array - like , shape = ( n_samples , ) : return :\"\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docstring[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, code_vocab_size, emb_dim, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(code_vocab_size, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_size, dropout=0.5, num_layers=2).to(device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        _, hidden_state = self.gru(embedded)\n",
    "        return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, docstring_vocab_size, emb_dim, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(docstring_vocab_size, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_size, dropout=0.5, num_layers=2).to(device)\n",
    "        self.linear = nn.Linear(hidden_size, docstring_vocab_size)\n",
    "\n",
    "    def forward(self, input, initial_state):\n",
    "        embedded = self.embedding(input)\n",
    "        output, _ = self.gru(embedded, initial_state)\n",
    "        output = self.linear(output)\n",
    "        return F.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, code, docstring):\n",
    "        dec_initial_state = self.encoder(code)\n",
    "        return self.decoder(docstring, dec_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_processor(fname='title_pp.dpkl'):\n",
    "    with open(fname, 'rb') as f:\n",
    "        pp = dpickle.load(f)\n",
    "    num_tokens = max(pp.id2token.keys()) + 1\n",
    "    return num_tokens, pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_decoder_inputs(decoder_np_vecs='train_title_vecs.npy'):\n",
    "    vectorized_title = np.load(decoder_np_vecs)\n",
    "    decoder_input_data = vectorized_title[:, :-1]\n",
    "    decoder_target_data = vectorized_title[:, 1:]\n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder_inputs(encoder_np_vecs='train_body_vecs.npy'):\n",
    "    vectorized_body = np.load(encoder_np_vecs)\n",
    "    encoder_input_data = vectorized_body\n",
    "    doc_length = encoder_input_data.shape[1]\n",
    "    return encoder_input_data, doc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data, encoder_seq_len = load_encoder_inputs('seq2seq/py_train_code_vecs_v2.npy')\n",
    "decoder_input_data, decoder_target_data = load_decoder_inputs('seq2seq/py_train_docstring_vecs_v2.npy')\n",
    "num_encoder_tokens, enc_pp = load_text_processor('seq2seq/py_code_processor_v2.dpkl')\n",
    "num_decoder_tokens, dec_pp = load_text_processor('seq2seq/py_docstring_processor_v2.dpkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(Encoder(num_encoder_tokens, emb_dim=800, hidden_size=1024),\n",
    "                Decoder(num_decoder_tokens, emb_dim=800, hidden_size=1024)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(20002, 800)\n",
       "    (gru): GRU(800, 1024, num_layers=2, dropout=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(14002, 800)\n",
       "    (gru): GRU(800, 1024, num_layers=2, dropout=0.5)\n",
       "    (linear): Linear(in_features=1024, out_features=14002, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = torch.LongTensor(encoder_input_data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 65,369,394 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "\n",
    "train_code_loader = torch.utils.data.DataLoader(encoder_input_data, batch_size=1000, shuffle=True)\n",
    "code_data_iter = iter(train_code_loader)\n",
    "train_docstring_loader = torch.utils.data.DataLoader(decoder_input_data, batch_size=1000, shuffle=True)\n",
    "docstring_data_iter = iter(train_docstring_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 14])\n",
      "torch.Size([1000, 14])\n"
     ]
    }
   ],
   "source": [
    "for i, code in enumerate(train_code_loader, 0):\n",
    "    if i > 1:\n",
    "        break\n",
    "    docstrings = decoder_input_data[i * BATCH_SIZE : (i+1) * BATCH_SIZE]\n",
    "    code = code.type(torch.LongTensor).to(device)\n",
    "    docstrings = torch.LongTensor(docstrings).to(device)\n",
    "    print(docstrings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================[Epoch 1, minibatch   300] loss: 9.206\n",
      "==============================[Epoch 1, minibatch   600] loss: 9.102\n",
      "==============================[Epoch 1, minibatch   900] loss: 9.060\n",
      "==============================[Epoch 1, minibatch  1200] loss: 9.029\n",
      "================================[Epoch 2, minibatch   300] loss: 9.016\n",
      "==============================[Epoch 2, minibatch   600] loss: 9.003\n",
      "==============================[Epoch 2, minibatch   900] loss: 8.996\n",
      "==============================[Epoch 2, minibatch  1200] loss: 8.976\n",
      "================================[Epoch 3, minibatch   300] loss: 8.977\n",
      "==============================[Epoch 3, minibatch   600] loss: 8.975\n",
      "==============================[Epoch 3, minibatch   900] loss: 8.974\n",
      "==============================[Epoch 3, minibatch  1200] loss: 8.957\n",
      "================================[Epoch 4, minibatch   300] loss: 8.961\n",
      "==============================[Epoch 4, minibatch   600] loss: 8.962\n",
      "==============================[Epoch 4, minibatch   900] loss: 8.962\n",
      "==============================[Epoch 4, minibatch  1200] loss: 8.948\n",
      "================================[Epoch 5, minibatch   300] loss: 8.952\n",
      "==============================[Epoch 5, minibatch   600] loss: 8.955\n",
      "==============================[Epoch 5, minibatch   900] loss: 8.956\n",
      "==============================[Epoch 5, minibatch  1200] loss: 8.941\n",
      "================================[Epoch 6, minibatch   300] loss: 8.946\n",
      "==============================[Epoch 6, minibatch   600] loss: 8.950\n",
      "==============================[Epoch 6, minibatch   900] loss: 8.951\n",
      "==============================[Epoch 6, minibatch  1200] loss: 8.937\n",
      "================================[Epoch 7, minibatch   300] loss: 8.942\n",
      "==============================[Epoch 7, minibatch   600] loss: 8.946\n",
      "==============================[Epoch 7, minibatch   900] loss: 8.948\n",
      "==============================[Epoch 7, minibatch  1200] loss: 8.934\n",
      "================================[Epoch 8, minibatch   300] loss: 8.939\n",
      "==============================[Epoch 8, minibatch   600] loss: 8.944\n",
      "==============================[Epoch 8, minibatch   900] loss: 8.945\n",
      "==============================[Epoch 8, minibatch  1200] loss: 8.932\n",
      "================================[Epoch 9, minibatch   300] loss: 8.937\n",
      "==============================[Epoch 9, minibatch   600] loss: 8.942\n",
      "==============================[Epoch 9, minibatch   900] loss: 8.943\n",
      "==============================[Epoch 9, minibatch  1200] loss: 8.931\n",
      "================================[Epoch 10, minibatch   300] loss: 8.935\n",
      "==============================[Epoch 10, minibatch   600] loss: 8.940\n",
      "==============================[Epoch 10, minibatch   900] loss: 8.942\n",
      "==============================[Epoch 10, minibatch  1200] loss: 8.929\n",
      "================================[Epoch 11, minibatch   300] loss: 8.934\n",
      "==============================[Epoch 11, minibatch   600] loss: 8.939\n",
      "==============================[Epoch 11, minibatch   900] loss: 8.941\n",
      "==============================[Epoch 11, minibatch  1200] loss: 8.928\n",
      "================================[Epoch 12, minibatch   300] loss: 8.933\n",
      "==============================[Epoch 12, minibatch   600] loss: 8.938\n",
      "==============================[Epoch 12, minibatch   900] loss: 8.940\n",
      "==============================[Epoch 12, minibatch  1200] loss: 8.927\n",
      "================================[Epoch 13, minibatch   300] loss: 8.932\n",
      "==============================[Epoch 13, minibatch   600] loss: 8.937\n",
      "==============================[Epoch 13, minibatch   900] loss: 8.939\n",
      "==============================[Epoch 13, minibatch  1200] loss: 8.926\n",
      "================================[Epoch 14, minibatch   300] loss: 8.931\n",
      "==============================[Epoch 14, minibatch   600] loss: 8.936\n",
      "==============================[Epoch 14, minibatch   900] loss: 8.938\n",
      "==============================[Epoch 14, minibatch  1200] loss: 8.926\n",
      "================================[Epoch 15, minibatch   300] loss: 8.931\n",
      "==============================[Epoch 15, minibatch   600] loss: 8.936\n",
      "==============================[Epoch 15, minibatch   900] loss: 8.938\n",
      "==============================[Epoch 15, minibatch  1200] loss: 8.925\n",
      "================================[Epoch 16, minibatch   300] loss: 8.931\n",
      "==============================[Epoch 16, minibatch   600] loss: 8.936\n",
      "==============================[Epoch 16, minibatch   900] loss: 8.937\n",
      "==============================[Epoch 16, minibatch  1200] loss: 8.925\n",
      "================================[Epoch 17, minibatch   300] loss: 8.930\n",
      "==============================[Epoch 17, minibatch   600] loss: 8.935\n",
      "==============================[Epoch 17, minibatch   900] loss: 8.937\n",
      "==============================[Epoch 17, minibatch  1200] loss: 8.924\n",
      "================================[Epoch 18, minibatch   300] loss: 8.929\n",
      "==============================[Epoch 18, minibatch   600] loss: 8.935\n",
      "==============================[Epoch 18, minibatch   900] loss: 8.937\n",
      "==============================[Epoch 18, minibatch  1200] loss: 8.924\n",
      "==Finished Training\n"
     ]
    }
   ],
   "source": [
    "#model.train()\n",
    "\n",
    "for epoch in range(18):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, code in enumerate(train_code_loader, 0):\n",
    "        dec_input = decoder_input_data[i * BATCH_SIZE : (i+1) * BATCH_SIZE]\n",
    "        dec_target = decoder_target_data[i * BATCH_SIZE : (i+1) * BATCH_SIZE]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        code = code.type(torch.LongTensor).to(device)\n",
    "        dec_input = torch.LongTensor(dec_input).to(device)\n",
    "        dec_target = torch.LongTensor(dec_target).to(device)\n",
    "        \n",
    "        code = torch.transpose(code, 0, 1)\n",
    "        dec_input = torch.transpose(dec_input, 0, 1)\n",
    "        dec_target = torch.transpose(dec_target, 0, 1)\n",
    "        outputs = model(code, dec_input)\n",
    "        outputs = outputs.view(-1, outputs.shape[2])\n",
    "        dec_target = dec_target.reshape(-1)\n",
    "        loss = criterion(outputs, dec_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            print(\"=\", end='')\n",
    "        if i % 300 == 299:    # print every 300 mini-batches\n",
    "            print('[Epoch %d, minibatch %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'tut2-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut2-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_code = holdout_code[:20]\n",
    "sub_docstring = holdout_docstring[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_code = enc_pp.transform(sub_code)\n",
    "sub_docstring = dec_pp.transform(sub_docstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_code = torch.transpose(torch.LongTensor(sub_code).to(device), 0, 1)\n",
    "sub_docstring = torch.transpose(torch.LongTensor(sub_docstring).to(device), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "outputs = model(sub_code, sub_docstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   13,     4,  4557,    16,    20,   167,     3,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [  760,    11,     4,  6280,   159,    17,   497,   467,   358,\n",
       "           94,     3,     0,     0,     0,     0],\n",
       "       [   31,     4,     1,   416,   340,     7,     5,   161,     3,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [   13,     5,  1859,  3963,  1317,    66,  2583,   948,    28,\n",
       "            3,    14,     0,     0,     0,     0],\n",
       "       [  293,    47,   233,    42,   721,     4,   561,   167,    88,\n",
       "            3,     0,     0,     0,     0,     0],\n",
       "       [   13,     4,  4557,    16,    20,   167,     3,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [  760,  1109,    65,    11,    34,   609,   111,     3,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [  293,     4,   233,   308,     6,    20,  1044,     3,   841,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [   22,   129,   103,   265,    42,   625,   267,    58,  2324,\n",
       "            3,     0,     0,     0,     0,     0],\n",
       "       [   22,   129,     4,   444,   145,    10,   396,     1,     3,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [   22,   428,    17,     1,     3,  8619,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [   22,   428,    17,   152,     3, 11721,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [   22,  1142,  4557,     1,  8619,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,   294],\n",
       "       [   22,  1142,   279,   147,     8,    34,  1230,     3,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [   22,     4,  2858,     6,     1,   478,    16,    20,    61,\n",
       "            3,     0,     0,     0,     0,     0],\n",
       "       [   31,  1939,   521,     3,   294,  2288,     0,   276,     0,\n",
       "         2018,     0,     0,     0,     0,     0],\n",
       "       [   25,    17,   311,  5786,   521,     3,     4,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [   13,     4,  4557,    16,    20,   167,     3,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [  293,     5,  4308,   332,    39,  1869,   859,    95,     3,\n",
       "         1641,     0,     0,     0,     0,     0],\n",
       "       [   31,  1939,   521,     3,  3118,     0,     0,     0,     0,\n",
       "            0,     0,     0,   276,     0,   276]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = np.argmax(outputs.to('cpu').detach().numpy(), axis=2).T\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "for i in range(outputs.shape[0]):\n",
    "    curr_sentence = []\n",
    "    for j in range(outputs.shape[1]):\n",
    "        if outputs[i][j] > 1:\n",
    "            curr_sentence.append(dec_pp.id2token[outputs[i][j]])\n",
    "    comments.append(curr_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return the identities from an item _end_\n",
      "todo in the rich event with our selected types d _end_\n",
      "get the events corresponding to a module _end_\n",
      "return a sorting hat identity using pip auto data _end_ this\n",
      "calculate user fields are inside the global item dict _end_\n",
      "return the identities from an item _end_\n",
      "todo null values in all django parameters _end_\n",
      "calculate the fields property of an issue _end_ outputs\n",
      "test whether json items are properly found into es _end_\n",
      "test whether the raw index is correctly _end_\n",
      "test instances with _end_ passe\n",
      "test instances with objects _end_ vl\n",
      "test refresh identities passe testing\n",
      "test refresh project field for all sources _end_\n",
      "test the extraction of params from an url _end_\n",
      "get elasticsearch mapping _end_ testing easy l activate\n",
      "file with nodes renaming mapping _end_ the\n",
      "return the identities from an item _end_\n",
      "calculate a jenkins job name converting logs dictionary _end_ upgrade\n",
      "get elasticsearch mapping _end_ arch l l\n"
     ]
    }
   ],
   "source": [
    "for comment in comments:\n",
    "    print(' '.join(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
