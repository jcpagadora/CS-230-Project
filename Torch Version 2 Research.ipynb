{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dill in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.3.2)\n",
      "Collecting ktext\n",
      "  Using cached ktext-0.40-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: pandas>=0.21.0 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ktext) (1.0.1)\n",
      "Requirement already satisfied: scipy in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ktext) (1.4.1)\n",
      "Collecting keras==2.2.4\n",
      "  Using cached Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "Processing ./.cache/pip/wheels/8b/d9/18/1ffaf26dc8375974075b3f58c683054babdf0a0d59d90557b2/pathos-0.2.6-py3-none-any.whl\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "Collecting textacy==0.6.2\n",
      "  Using cached textacy-0.6.2-py2.py3-none-any.whl (142 kB)\n",
      "Requirement already satisfied: msgpack in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ktext) (0.6.1)\n",
      "Requirement already satisfied: more-itertools in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ktext) (8.2.0)\n",
      "Requirement already satisfied: dask in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ktext) (2.11.0)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ktext) (5.3.1)\n",
      "Collecting pyarrow\n",
      "  Using cached pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7 MB)\n",
      "Collecting msgpack-numpy\n",
      "  Using cached msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: six in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ktext) (1.14.0)\n",
      "Requirement already satisfied: numpy in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ktext) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas>=0.21.0->ktext) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas>=0.21.0->ktext) (2.8.1)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: h5py in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras==2.2.4->ktext) (2.10.0)\n",
      "Processing ./.cache/pip/wheels/fc/13/89/f55a8959ba9e54898fc2f6436e8f8326a5a8fb40f1c71c1d62/ppft-1.6.6.2-py3-none-any.whl\n",
      "Requirement already satisfied: dill>=0.3.2 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pathos->ktext) (0.3.2)\n",
      "Processing ./.cache/pip/wheels/af/2b/9b/5c0341ebf3f5dac0ecdf4ec463b1909f5a304e182ac45e53b3/multiprocess-0.70.10-py3-none-any.whl\n",
      "Processing ./.cache/pip/wheels/ce/39/65/a5c5edbe8ec4d429578cb5242f01efdc92a54b4abac45b63a0/pox-0.2.8-py3-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow->ktext) (3.11.4)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Using cached tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow->ktext) (1.11.2)\n",
      "Collecting astunparse==1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Using cached grpcio-1.33.2-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow->ktext) (0.34.2)\n",
      "Processing ./.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc/termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Using cached tensorboard-2.3.0-py3-none-any.whl (6.8 MB)\n",
      "Requirement already satisfied: spacy>=2.0.0 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from textacy==0.6.2->ktext) (2.3.2)\n",
      "Requirement already satisfied: tqdm>=4.11.1 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from textacy==0.6.2->ktext) (4.42.1)\n",
      "Processing ./.cache/pip/wheels/f9/f0/23/aefbdde40e915c67830ebecb55be2344a8b6e95fe3ce3ccf96/pyemd-0.5.1-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting cachetools>=2.0.0\n",
      "  Using cached cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Processing ./.cache/pip/wheels/f1/47/dc/48b860b321b7dda1073ced6eaea164a6b94f25936b10eba32f/ftfy-4.4.3-py3-none-any.whl\n",
      "Collecting ijson>=2.3\n",
      "  Using cached ijson-3.1.2.post0-cp36-cp36m-manylinux2010_x86_64.whl (127 kB)\n",
      "Requirement already satisfied: cytoolz>=0.8.0 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from textacy==0.6.2->ktext) (0.10.1)\n",
      "Processing ./.cache/pip/wheels/79/c3/a1/cbdd8b154234b3e571d121b65be7d53354cc77e223e8f271c8/python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting pyphen>=0.9.4\n",
      "  Downloading Pyphen-0.10.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from textacy==0.6.2->ktext) (2.22.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.0 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from textacy==0.6.2->ktext) (0.22.1)\n",
      "Requirement already satisfied: networkx>=1.11 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from textacy==0.6.2->ktext) (2.4)\n",
      "Collecting unidecode>=0.04.19\n",
      "  Using cached Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.9.2->tensorflow->ktext) (45.2.0.post20200210)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.23.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 20.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow->ktext) (1.0.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (0.9.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (7.4.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.0.0->textacy==0.6.2->ktext) (0.8.0)\n",
      "Requirement already satisfied: wcwidth in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ftfy<5.0.0,>=4.2.0->textacy==0.6.2->ktext) (0.1.8)\n",
      "Requirement already satisfied: html5lib in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ftfy<5.0.0,>=4.2.0->textacy==0.6.2->ktext) (1.0.1)\n",
      "Requirement already satisfied: toolz>=0.8.0 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from cytoolz>=0.8.0->textacy==0.6.2->ktext) (0.10.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.10.0->textacy==0.6.2->ktext) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.10.0->textacy==0.6.2->ktext) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.10.0->textacy==0.6.2->ktext) (1.25.10)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.10.0->textacy==0.6.2->ktext) (3.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn>=0.17.0->textacy==0.6.2->ktext) (0.14.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: decorator>=4.3.0 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from networkx>=1.11->textacy==0.6.2->ktext) (4.4.1)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
      "  Using cached rsa-4.6-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->ktext) (2.0.0)\n",
      "Requirement already satisfied: webencodings in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from html5lib->ftfy<5.0.0,>=4.2.0->textacy==0.6.2->ktext) (0.5.1)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->ktext) (2.2.0)\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras, ppft, multiprocess, pox, pathos, tensorflow-estimator, astunparse, grpcio, opt-einsum, absl-py, gast, google-pasta, termcolor, oauthlib, requests-oauthlib, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, google-auth-oauthlib, markdown, tensorboard-plugin-wit, tensorboard, tensorflow, pyemd, ftfy, ijson, python-levenshtein, pyphen, unidecode, textacy, pyarrow, msgpack-numpy, ktext\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.1.1 ftfy-4.4.3 gast-0.3.3 google-auth-1.23.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.33.2 ijson-3.1.2.post0 keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.2 ktext-0.40 markdown-3.3.3 msgpack-numpy-0.4.7.1 multiprocess-0.70.10 oauthlib-3.1.0 opt-einsum-3.3.0 pathos-0.2.6 pox-0.2.8 ppft-1.6.6.2 pyarrow-2.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyemd-0.5.1 pyphen-0.10.0 python-levenshtein-0.12.0 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0 termcolor-1.1.0 textacy-0.6.2 unidecode-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dill\n",
    "!pip install ktext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "import dill as dpickle\n",
    "\n",
    "from ktext.preprocess import processor\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_files(data_path:str):\n",
    "    \"\"\"\n",
    "    Read data from directory\n",
    "    \"\"\"\n",
    "    PATH = Path(data_path)\n",
    "\n",
    "    with open(PATH/'train.function', 'r') as f:\n",
    "        t_enc = f.readlines()\n",
    "\n",
    "    with open(PATH/'valid.function', 'r') as f:\n",
    "        v_enc = f.readlines()\n",
    "\n",
    "    # combine train and validation and let keras split it randomly for you\n",
    "    tv_enc = t_enc + v_enc\n",
    "\n",
    "    with open(PATH/'test.function', 'r') as f:\n",
    "        h_enc = f.readlines()\n",
    "\n",
    "    with open(PATH/'train.docstring', 'r') as f:\n",
    "        t_dec = f.readlines()\n",
    "\n",
    "    with open(PATH/'valid.docstring', 'r') as f:\n",
    "        v_dec = f.readlines()\n",
    "\n",
    "    # combine train and validation and let keras split it randomly for you\n",
    "    tv_dec = t_dec + v_dec\n",
    "\n",
    "    with open(PATH/'test.docstring', 'r') as f:\n",
    "        h_dec = f.readlines()\n",
    "\n",
    "    return tv_enc, h_enc, tv_dec, h_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_code, holdout_code, train_docstring, holdout_docstring = read_training_files('processed_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def batch_generator batch_size data labels None n_batches int np ceil len data float batch_size idx np random permutation len data data_shuffled data idx if labels is not None labels_shuffled labels idx for i in range n_batches start i batch_size end start batch_size if labels is not None yield data_shuffled start end labels_shuffled start end else yield data_shuffled start end\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_code[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"generates batches of samples : param data : array - like , shape = ( n_samples , n_features ) : param labels : array - like , shape = ( n_samples , ) : return :\"\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docstring[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, code_vocab_size, emb_dim, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(code_vocab_size, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_size, dropout=0.5).cuda()\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        _, hidden_state = self.gru(embedded)\n",
    "        return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, docstring_vocab_size, emb_dim, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(docstring_vocab_size, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_size, dropout=0.5).cuda()\n",
    "        self.linear = nn.Linear(hidden_size, docstring_vocab_size)\n",
    "\n",
    "    def forward(self, input, initial_state):\n",
    "        embedded = self.embedding(input)\n",
    "        output, _ = self.gru(embedded, initial_state)\n",
    "        return F.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input):\n",
    "        dec_initial_state = self.encoder(input)\n",
    "        return self.decoder(input, dec_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_processor(fname='title_pp.dpkl'):\n",
    "    \"\"\"\n",
    "    Load preprocessors from disk.\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname: str\n",
    "        file name of ktext.proccessor object\n",
    "    Returns\n",
    "    -------\n",
    "    num_tokens : int\n",
    "        size of vocabulary loaded into ktext.processor\n",
    "    pp : ktext.processor\n",
    "        the processor you are trying to load\n",
    "    Typical Usage:\n",
    "    -------------\n",
    "    num_decoder_tokens, title_pp = load_text_processor(fname='title_pp.dpkl')\n",
    "    num_encoder_tokens, body_pp = load_text_processor(fname='body_pp.dpkl')\n",
    "    \"\"\"\n",
    "    # Load files from disk\n",
    "    with open(fname, 'rb') as f:\n",
    "        pp = dpickle.load(f)\n",
    "\n",
    "    num_tokens = max(pp.id2token.keys()) + 1\n",
    "    print(f'Size of vocabulary for {fname}: {num_tokens:,}')\n",
    "    return num_tokens, pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_decoder_inputs(decoder_np_vecs='train_title_vecs.npy'):\n",
    "    \"\"\"\n",
    "    Load decoder inputs.\n",
    "    Parameters\n",
    "    ----------\n",
    "    decoder_np_vecs : str\n",
    "        filename of serialized numpy.array of decoder input (issue title)\n",
    "    Returns\n",
    "    -------\n",
    "    decoder_input_data : numpy.array\n",
    "        The data fed to the decoder as input during training for teacher forcing.\n",
    "        This is the same as `decoder_np_vecs` except the last position.\n",
    "    decoder_target_data : numpy.array\n",
    "        The data that the decoder data is trained to generate (issue title).\n",
    "        Calculated by sliding `decoder_np_vecs` one position forward.\n",
    "    \"\"\"\n",
    "    vectorized_title = np.load(decoder_np_vecs)\n",
    "    # For Decoder Input, you don't need the last word as that is only for prediction\n",
    "    # when we are training using Teacher Forcing.\n",
    "    decoder_input_data = vectorized_title[:, :-1]\n",
    "\n",
    "    # Decoder Target Data Is Ahead By 1 Time Step From Decoder Input Data (Teacher Forcing)\n",
    "    decoder_target_data = vectorized_title[:, 1:]\n",
    "\n",
    "    print(f'Shape of decoder input: {decoder_input_data.shape}')\n",
    "    print(f'Shape of decoder target: {decoder_target_data.shape}')\n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder_inputs(encoder_np_vecs='train_body_vecs.npy'):\n",
    "    \"\"\"\n",
    "    Load variables & data that are inputs to encoder.\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoder_np_vecs : str\n",
    "        filename of serialized numpy.array of encoder input (issue title)\n",
    "    Returns\n",
    "    -------\n",
    "    encoder_input_data : numpy.array\n",
    "        The issue body\n",
    "    doc_length : int\n",
    "        The standard document length of the input for the encoder after padding\n",
    "        the shape of this array will be (num_examples, doc_length)\n",
    "    \"\"\"\n",
    "    vectorized_body = np.load(encoder_np_vecs)\n",
    "    # Encoder input is simply the body of the issue text\n",
    "    encoder_input_data = vectorized_body\n",
    "    doc_length = encoder_input_data.shape[1]\n",
    "    print(f'Shape of encoder input: {encoder_input_data.shape}')\n",
    "    return encoder_input_data, doc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder input: (1227989, 55)\n",
      "Shape of decoder input: (1227989, 14)\n",
      "Shape of decoder target: (1227989, 14)\n",
      "Size of vocabulary for seq2seq/py_code_processor_v2.dpkl: 20,002\n",
      "Size of vocabulary for seq2seq/py_docstring_processor_v2.dpkl: 14,002\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data, encoder_seq_len = load_encoder_inputs('seq2seq/py_train_code_vecs_v2.npy')\n",
    "decoder_input_data, decoder_target_data = load_decoder_inputs('seq2seq/py_train_docstring_vecs_v2.npy')\n",
    "num_encoder_tokens, enc_pp = load_text_processor('seq2seq/py_code_processor_v2.dpkl')\n",
    "num_decoder_tokens, dec_pp = load_text_processor('seq2seq/py_docstring_processor_v2.dpkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-2408d253943c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = Seq2Seq(Encoder(num_encoder_tokens, emb_dim=400, hidden_size=256),\n\u001b[0m\u001b[1;32m      2\u001b[0m                 Decoder(num_decoder_tokens, emb_dim=400, hidden_size=256)).to(device)\n",
      "\u001b[0;32m<ipython-input-64-2b55cfea11c3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, code_vocab_size, emb_dim, hidden_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Resets _flat_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(Encoder(num_encoder_tokens, emb_dim=400, hidden_size=256),\n",
    "                Decoder(num_decoder_tokens, emb_dim=400, hidden_size=256)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = torch.LongTensor(encoder_input_data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 18,210,802 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "\n",
    "train_code_loader = torch.utils.data.DataLoader(encoder_input_data, batch_size=1000, shuffle=True)\n",
    "code_data_iter = iter(train_code_loader)\n",
    "train_docstring_loader = torch.utils.data.DataLoader(decoder_input_data, batch_size=1000, shuffle=True)\n",
    "docstring_data_iter = iter(train_docstring_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-c8c72e9618bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdocstrings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocstrings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdocstrings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-f6a7850cb208>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdec_initial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_initial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-5f01113b5466>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, initial_state)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(12):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, code in enumerate(train_code_loader, 0):\n",
    "        docstrings = decoder_input_data[i * BATCH_SIZE : (i+1) * BATCH_SIZE]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        code = code.type(torch.LongTensor).to(device)\n",
    "        docstrings = torch.LongTensor(docstrings).to(device)\n",
    "        \n",
    "        code = torch.transpose(code, 0, 1)\n",
    "        docstrings = torch.transpose(docstrings, 0, 1)\n",
    "        \n",
    "        outputs = model(code)\n",
    "        outputs = outputs.view(-1, outputs.shape[2])\n",
    "        docstrings = docstrings.reshape(-1)\n",
    "        loss = criterion(outputs, docstrings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            print(\"=\", end='')\n",
    "        if i % 300 == 299:    # print every 300 mini-batches\n",
    "            print('[Epoch %d, minibatch %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
